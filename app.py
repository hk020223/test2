import streamlit as st
import pandas as pd
import os
import glob
from langchain_community.document_loaders import PyPDFLoader
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import PromptTemplate

# -----------------------------------------------------------------------------
# [1] ì„œë²„ ì„¤ì • ë° ë°ì´í„° ë¡œë“œ
# -----------------------------------------------------------------------------
st.set_page_config(page_title="KW-ê°•ì˜ë§ˆìŠ¤í„°", page_icon="ğŸ“", layout="wide")
api_key = os.environ.get("GOOGLE_API_KEY", "")

# ì§€ì‹ ë² ì´ìŠ¤ ë¡œë”© í•¨ìˆ˜ (data í´ë”ì˜ ëª¨ë“  PDF ì½ê¸°)
@st.cache_resource(show_spinner="í•™êµ ì •ë³´ë¥¼ í•™ìŠµí•˜ëŠ” ì¤‘ì…ë‹ˆë‹¤... (ì•½ 1ë¶„ ì†Œìš”)")
def load_knowledge_base():
    all_content = ""
    
    # 'data' í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„± (ì—ëŸ¬ ë°©ì§€ìš©)
    if not os.path.exists("data"):
        os.makedirs("data")
        return ""

    # data í´ë” ì•ˆì˜ ëª¨ë“  .pdf íŒŒì¼ ì°¾ê¸°
    pdf_files = glob.glob("data/*.pdf")
    
    if not pdf_files:
        return ""

    # ê° PDF íŒŒì¼ì„ ìˆœì„œëŒ€ë¡œ ì½ì–´ì„œ í…ìŠ¤íŠ¸ í•©ì¹˜ê¸°
    for pdf_file in pdf_files:
        try:
            loader = PyPDFLoader(pdf_file)
            pages = loader.load_and_split()
            
            # íŒŒì¼ëª…ì„ í—¤ë”ë¡œ ì¶”ê°€í•´ì„œ AIê°€ ì¶œì²˜ë¥¼ ì•Œê²Œ í•¨
            filename = os.path.basename(pdf_file)
            all_content += f"\n\n--- [ë¬¸ì„œ ì‹œì‘: {filename}] ---\n"
            
            for page in pages:
                all_content += page.page_content
                
        except Exception as e:
            print(f"Error loading {pdf_file}: {e}")
            continue
            
    return all_content

# ì•± ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ ì‹¤í–‰ë˜ì–´ ëª¨ë“  PDFë¥¼ ë©”ëª¨ë¦¬ì— ì˜¬ë¦¼
PRE_LEARNED_DATA = load_knowledge_base()

# ê°•ì˜ ë°ì´í„°ë² ì´ìŠ¤ (ì‹œê°„í‘œìš© - ì´ì „ê³¼ ë™ì¼)
@st.cache_data
def load_course_db():
    return pd.DataFrame([
        {"ê³¼ëª©ëª…": "ì¸ê³µì§€ëŠ¥ê¸°ì´ˆ", "êµìˆ˜": "ê¹€êµìˆ˜", "ì‹œê°„": "ì›”1,2,3", "ì˜ì—­": "ì „ê³µ", "ê³¼ì œë¹„ì¤‘": 40, "ì‹œí—˜ë¹„ì¤‘": 60, "íŒ€í”Œ": "ìœ "},
        {"ê³¼ëª©ëª…": "ì „ìíšŒë¡œ1", "êµìˆ˜": "ì´êµìˆ˜", "ì‹œê°„": "í™”4,5,6", "ì˜ì—­": "ì „ê³µ", "ê³¼ì œë¹„ì¤‘": 20, "ì‹œí—˜ë¹„ì¤‘": 80, "íŒ€í”Œ": "ë¬´"},
        {"ê³¼ëª©ëª…": "ë°ì´í„°ë² ì´ìŠ¤", "êµìˆ˜": "ìµœêµìˆ˜", "ì‹œê°„": "ëª©4,5,6", "ì˜ì—­": "ì „ê³µ", "ê³¼ì œë¹„ì¤‘": 30, "ì‹œí—˜ë¹„ì¤‘": 70, "íŒ€í”Œ": "ìœ "},
        {"ê³¼ëª©ëª…": "ê´‘ìš´ì¸ì„±", "êµìˆ˜": "ì •êµìˆ˜", "ì‹œê°„": "ê¸ˆ1,2", "ì˜ì—­": "êµì–‘", "ê³¼ì œë¹„ì¤‘": 10, "ì‹œí—˜ë¹„ì¤‘": 90, "íŒ€í”Œ": "ë¬´"},
        {"ê³¼ëª©ëª…": "ëŒ€í•™ì˜ì–´", "êµìˆ˜": "Brown", "ì‹œê°„": "ì›”7,8", "ì˜ì—­": "êµì–‘", "ê³¼ì œë¹„ì¤‘": 30, "ì‹œí—˜ë¹„ì¤‘": 70, "íŒ€í”Œ": "ìœ "}
    ])

course_db = load_course_db()

# -----------------------------------------------------------------------------
# [2] AI ì—”ì§„
# -----------------------------------------------------------------------------
def ask_ai(question):
    if not api_key:
        return "âš ï¸ ì„œë²„ì— API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. (Render Settings í™•ì¸)"
    
    if not PRE_LEARNED_DATA: 
        return "âš ï¸ í•™ìŠµëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. VS Codeì˜ 'data' í´ë”ì— PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”."

    try:
        # ì •ë³´ê°€ ë§ìœ¼ë¯€ë¡œ temperatureë¥¼ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ íŒ©íŠ¸ ìœ„ì£¼ ë‹µë³€
        # ìˆ˜ì •: ëª¨ë¸ëª…ì„ 'gemini-1.5-flash-latest'ë¡œ ë³€ê²½í•˜ì—¬ ì¸ì‹ ì˜¤ë¥˜ í•´ê²° ì‹œë„
        # ë§Œì•½ ì—¬ì „íˆ ì•ˆ ëœë‹¤ë©´ 'gemini-pro'ë¡œ ë³€ê²½í•´ë³´ì„¸ìš”.
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash-latest", temperature=0)
        
        template = """
        ë„ˆëŠ” ê´‘ìš´ëŒ€í•™êµ í•™ì‚¬ ì „ë¬¸ ìƒë‹´ ë¹„ì„œ 'KW-ê°•ì˜ë§ˆìŠ¤í„°'ì•¼.
        ë„ˆëŠ” ì•„ë˜ ì œê³µëœ [í•™ìŠµëœ PDF ë¬¸ì„œë“¤]ì˜ ë‚´ìš©ì„ ì™„ë²½í•˜ê²Œ ìˆ™ì§€í•˜ê³  ìˆì–´.
        
        [ì§€ì‹œì‚¬í•­]
        1. ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì€ ì˜¤ì§ ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ì— ê¸°ë°˜í•´ì„œ ì‘ì„±í•´.
        2. ë‹µë³€í•  ë•Œ "ì°¸ê³ í•œ ë¬¸ì„œì˜ ì´ë¦„(ì˜ˆ: ì¥í•™ê¸ˆê·œì •.pdf)"ì„ ì–¸ê¸‰í•´ì£¼ë©´ ë” ì¢‹ì•„.
        3. ë¬¸ì„œì— ì—†ëŠ” ë‚´ìš©ì€ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µí•´.

        [í•™ìŠµëœ PDF ë¬¸ì„œë“¤]
        {context}

        [í•™ìƒì˜ ì§ˆë¬¸]
        {question}
        """
        prompt = PromptTemplate(template=template, input_variables=["context", "question"])
        chain = prompt | llm
        response = chain.invoke({"context": PRE_LEARNED_DATA, "question": question})
        return response.content
    except Exception as e:
        return f"âŒ AI ì˜¤ë¥˜: {str(e)}"

# -----------------------------------------------------------------------------
# [3] UI êµ¬ì„±
# -----------------------------------------------------------------------------
st.sidebar.title("ğŸ“ KW-ê°•ì˜ë§ˆìŠ¤í„°")
# glob ëª¨ë“ˆì´ ì—†ëŠ” ê²½ìš° ëŒ€ë¹„
try:
    pdf_count = len(glob.glob("data/*.pdf"))
except:
    pdf_count = 0
st.sidebar.info(f"ğŸ“š í˜„ì¬ {pdf_count}ê°œì˜ ë¬¸ì„œë¥¼ í•™ìŠµí–ˆìŠµë‹ˆë‹¤.")

menu = st.sidebar.radio("ë©”ë‰´", ["AI í•™ì‚¬ ì§€ì‹ì¸", "ì´ìˆ˜í•™ì  ì§„ë‹¨", "ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ"])

if menu == "AI í•™ì‚¬ ì§€ì‹ì¸":
    st.header("ğŸ¤– AI í•™ì‚¬ ì§€ì‹ì¸")
    st.caption("ì—…ë¡œë“œëœ PDF ë¬¸ì„œë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    if user_input := st.chat_input("ì§ˆë¬¸í•˜ì„¸ìš” (ì˜ˆ: ì´ë²ˆ í•™ê¸° ì¥í•™ê¸ˆ ê¸°ì¤€ì´ ë­ì•¼?)"):
        st.session_state.messages.append({"role": "user", "content": user_input})
        with st.chat_message("user"):
            st.markdown(user_input)

        with st.chat_message("assistant"):
            with st.spinner("ë¬¸ì„œë¥¼ ê²€ìƒ‰ ì¤‘ì…ë‹ˆë‹¤..."):
                answer = ask_ai(user_input)
                st.markdown(answer)
        st.session_state.messages.append({"role": "assistant", "content": answer})

elif menu == "ì´ìˆ˜í•™ì  ì§„ë‹¨":
    st.header("ğŸ“Š ì¡¸ì—… ì´ìˆ˜ í˜„í™©")
    col1, col2 = st.columns(2)
    with col1:
        major = st.number_input("ì „ê³µ ì´ìˆ˜ í•™ì ", 0, 130, 45)
        ge = st.number_input("êµì–‘ ì´ìˆ˜ í•™ì ", 0, 130, 20)
    with col2:
        total = major + ge
        st.metric("í˜„ì¬ ì´ ì´ìˆ˜", f"{total} / 130")
        st.progress(total/130)

elif menu == "ìŠ¤ë§ˆíŠ¸ ì‹œê°„í‘œ":
    st.header("ğŸ“… ì‹œê°„í‘œ ìë™ ìƒì„±")
    if st.button("ê³µê°• ê³ ë ¤ ì‹œê°„í‘œ ì¶”ì²œë°›ê¸°"):
        res = course_db.sample(3)
        st.table(res[['ê³¼ëª©ëª…', 'êµìˆ˜', 'ì‹œê°„', 'ì˜ì—­']])